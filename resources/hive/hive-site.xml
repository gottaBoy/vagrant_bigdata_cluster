<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <property>
		<name>hive.metastore.local</name>
		<value>false</value>
		<description>使用本机mysql服务器存储元数据。这种存储方式需要在本地运行一个mysql服>务器</description>
    </property>
    <property>
		<name>system:java.io.tmpdir</name>
		<value>/home/vagrant/apps/hive/tmpdir</value>
    </property>

    <property>
		<name>javax.jdo.option.ConnectionURL</name>
		<value>jdbc:mysql://hdp103:3306/hive?createDatabaseIfNotExist=true&amp;useSSL=false</value>
    </property>
    <property>
		<name>javax.jdo.option.ConnectionDriverName</name>
		<value>com.mysql.jdbc.Driver</value>
    </property>
    <property>
		<name>javax.jdo.option.ConnectionUserName</name>
		<value>hive</value>
    </property>
    <property>
		<name>javax.jdo.option.ConnectionPassword</name>
		<value>hive</value>
		<description>password to use against metastore database</description>
    </property>
    <property>
		<name>hive.metastore.warehouse.dir</name>
		<value>/user/hive/warehouse</value>
    </property>
    <property>
		<name>datanucleus.autoCreateSchema</name>
		<value>false</value>
    </property>
    <property>
		<name>hive.metastore.schema.verification</name>
		<value>false</value>
    </property>
    <!--显示数据库名称-->
    <property>
		<name>hive.cli.print.current.db</name>
		<value>true</value>
    </property>
    <property>
		<name>hive.cli.print.header</name>
		<value>true</value>
    </property>
    <property>
		<name>hive.server2.thrift.port</name>
		<value>10000</value>
    </property>

    <property>
		<name>hive.server2.thrift.bind.host</name>
		<value>hdp101</value>
    </property>
    <property>
		<name>hive.metastore.event.db.notification.api.auth</name>
		<value>false</value>
    </property>
	<!--Spark依赖位置（注意：端口号8020必须和namenode的端口号一致）-->
	<!-- wget https://mirrors.huaweicloud.com/apache/spark/spark-3.0.0/spark-3.0.0-bin-without-hadoop.tgz -->
	<property>
		<name>spark.yarn.jars</name>
		<value>hdfs://hadoop102:8020/spark-jars/*</value>
	</property>
	
	<!--Hive执行引擎-->
	<property>
		<name>hive.execution.engine</name>
		<value>spark</value>
	</property>
</configuration>
